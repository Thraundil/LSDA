{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsda/lsdaenv/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import AveragePooling2D, Flatten, Dropout, Dense\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "verbose = True\n",
    "\n",
    "os.chdir('/mnt/LSDA/CNN/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "class Metrics(Callback):\n",
    "    def __init__(self, best_val_score):\n",
    "        super().__init__()\n",
    "        self.best_val_score = best_val_score\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_f1s = []\n",
    "        self.val_recalls = []\n",
    "        self.val_precisions = []\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_predict = (np.asarray(self.model.predict(validation_features))).round()\n",
    "        val_targ = validation_labels\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='micro')\n",
    "        _val_recall = recall_score(val_targ, val_predict, average='micro')\n",
    "        _val_precision = precision_score(val_targ, val_predict, average='micro')\n",
    "        self.val_f1s.append(_val_f1)\n",
    "        self.val_recalls.append(_val_recall)\n",
    "        self.val_precisions.append(_val_precision)\n",
    "        print(' — val_f1: %f — val_precision: %f — val_recall %f' %(_val_f1, _val_precision, _val_recall))\n",
    "        if _val_f1 > self.best_val_score:\n",
    "            print('Better model found, saving model with val score %s'%_val_f1)\n",
    "            self.model.save('best_full_model.h5')\n",
    "            self.best_val_score = _val_f1\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_FOLDER = '/home/lsda/features'\n",
    "LABELS_FOLDER = '/mnt/LSDA/labels'\n",
    "\n",
    "DATASET = 'validation'\n",
    "f = h5py.File(os.path.join(FEATURES_FOLDER,DATASET,'incept.hdf5')); \n",
    "validation_features = f['a'][1:]; f.close()\n",
    "validation_labels = np.load(os.path.join(LABELS_FOLDER, DATASET, 'labels.npz'))['arr_0'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lsda/lsdaenv/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# %%============================================================================\n",
    "# BUILD TOP LAYER\n",
    "#===============================================================================\n",
    "# Load files\n",
    "# NOTE: These files may be too large to fit in memory!\n",
    "\n",
    "# Load features extracted from the CNN\n",
    "# f = h5py.File('incept.hdf5')\n",
    "# CNN_features = f['a']\n",
    "# f.close()\n",
    "#CNN_features = np.random.rand(no_imgs_batch,2048) # test construction\n",
    "# train_data = np.load(open('bottleneck_features_train.npy'))\n",
    "#if verbose:\n",
    "#    print('CNN_features shape: ', CNN_features.shape, '\\n')\n",
    "\n",
    "# validation_data = ...\n",
    "# validation_labels = ...\n",
    "\n",
    "model_top_layer = Sequential()\n",
    "# model_top_layer.add(Flatten(input_shape=(1,2048))) # the comma in (2048,) is important!\n",
    "model_top_layer.add(Dense(1024, activation='sigmoid', input_shape=(2048,), name='dense_1'))\n",
    "#model_top_layer.add(Dropout(0.5))\n",
    "model_top_layer.add(Dense(229,\n",
    "                kernel_initializer='he_uniform',\n",
    "                activation='sigmoid',\n",
    "                name='dense_2'))\n",
    "model_top_layer.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',f1])\n",
    "\n",
    "model_top_layer.load_weights('best_val_model.h5')\n",
    "val_predict = (np.asarray(model_top_layer.predict(validation_features))).round()\n",
    "_val_f1 = f1_score(val_predict, validation_labels, average='micro')\n",
    "metrics = Metrics(_val_f1)\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='./Tensorboard/logs_%s'%time.time(),\n",
    "                         histogram_freq=0,\n",
    "                         write_graph=True,\n",
    "                         write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%============================================================================\n",
    "# TRAIN TOP LAYER\n",
    "#===============================================================================\n",
    "#if verbose:\n",
    "#    print('Training top layer..')\n",
    "#\n",
    "#model_top_layer.fit(CNN_features, y_train,\n",
    "#          epochs=50,\n",
    "#          batch_size=32,\n",
    "#          callbacks=[tbCallBack]) # , validation_data=(validation_data, validation_labels)\n",
    "# model_top_layer.save_weights('top_layer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full model compiled.\n",
      "Here are some details regarding the architecture:\n",
      "CNN layers:\n",
      "First CNN layer input shape:  (None, 299, 299, 3)\n",
      "...\n",
      "Last CNN layer output shape:  (None, 8, 8, 2048) \n",
      "\n",
      "Flatten layer:\n",
      "Flatten layer input shape:  (None, 8, 8, 2048)\n",
      "Flatten layer output shape:  (None, 1, 1, 2048) \n",
      "\n",
      "Average pooling layer:\n",
      "AvPool layer input shape:  (None, 1, 1, 2048)\n",
      "AvPool layer output shape:  (None, 2048) \n",
      "\n",
      "Top layers:\n",
      "First top_layer layer input shape:  (None, 2048)\n",
      "...\n",
      "Last top_layer layer output shape:  (None, 229) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%============================================================================\n",
    "# BUILD FULL MODEL\n",
    "#===============================================================================\n",
    "img_size=299\n",
    "model_full = Sequential()\n",
    "\n",
    "# Load and freeze (all but last few) InceptionV3 CNN layers\n",
    "incep_model = InceptionV3(weights=\"imagenet\",\n",
    "                          include_top=False,\n",
    "                          input_shape=(img_size, img_size, 3))\n",
    "# Freeze all but the last inception modules (https://arxiv.org/pdf/1409.4842.pdf)\n",
    "# To see list of layers, run:\n",
    "# for i,layer in enumerate(incep_model.layers):\n",
    "#     print(f'Layer {i}:', layer)\n",
    "# Last and second to last layers begins in layer 280 and 249, respectively (using 1-indexing)\n",
    "last_frozen_layer = 279\n",
    "for layer in incep_model.layers[:last_frozen_layer]:\n",
    "    layer.trainable = False\n",
    "for layer in incep_model.layers[last_frozen_layer:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_full.add(incep_model)\n",
    "model_full.add(AveragePooling2D(pool_size=(8,8)))\n",
    "model_full.add(Flatten())\n",
    "# model_top_layer.load_weights('model_top_layer_weights_path')\n",
    "model_full.add(model_top_layer)\n",
    "\n",
    "model_full.compile(optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',f1])\n",
    "\n",
    "if verbose:\n",
    "    print('')\n",
    "    print('Full model compiled.')\n",
    "    print('Here are some details regarding the architecture:')\n",
    "    for i,chunk in enumerate(model_full.layers):\n",
    "        if i == 0: # unpack CNN\n",
    "            print('CNN layers:')\n",
    "            print('First CNN layer input shape: ', chunk.layers[0].input_shape)\n",
    "            print('...')\n",
    "            print('Last CNN layer output shape: ', chunk.layers[-1].output_shape, '\\n')\n",
    "        if i == 1: # Flatten layer\n",
    "            print('Flatten layer:')\n",
    "            print('Flatten layer input shape: ', chunk.input_shape)\n",
    "            print('Flatten layer output shape: ', chunk.output_shape, '\\n')\n",
    "        if i == 2: # AveragePooling2D\n",
    "            print('Average pooling layer:')\n",
    "            print('AvPool layer input shape: ', chunk.input_shape)\n",
    "            print('AvPool layer output shape: ', chunk.output_shape, '\\n')\n",
    "        if i == 3: # unpack top_layer\n",
    "            print('Top layers:')\n",
    "            print('First top_layer layer input shape: ', chunk.layers[0].input_shape)\n",
    "            print('...')\n",
    "            print('Last top_layer layer output shape: ', chunk.layers[-1].output_shape, '\\n')\n",
    "            # for j,layer in enumerate(chunk.layers):\n",
    "            #     print(f'Layer {j} input shape: ', layer.input_shape)\n",
    "            #     print(f'Layer {j} output shape: ', layer.output_shape)\n",
    "    # from keras.utils import plot_model\n",
    "    # plot_model(model_full, to_file='full_model.png', show_shapes=True) # spits out a flow-chart of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%============================================================================\n",
    "# IMPORT DATA\n",
    "#===============================================================================\n",
    "no_labels = 228\n",
    "\n",
    "train_dir = '../data/raw_images/train/'\n",
    "image_files = os.listdir(train_dir)\n",
    "image_files = np.random.permutation(image_files)\n",
    "no_imgs_tot = len(image_files)\n",
    "\n",
    "annotations_dir = '../data/labels/train/labels.npz'\n",
    "train_labels = np.load(annotations_dir)['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Save_model(Callback):\n",
    " \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save('full_model.h5')\n",
    "        return\n",
    "save_model = Save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "x_train shape:  (4000, 299, 299, 3)\n",
      "y_train shape:  (4000, 229)\n",
      "Fine-tuning full model..\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 84s 10s/step - loss: 24.4383 - acc: 0.1190 - f1: 0.3674\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 77s 10s/step - loss: 24.1095 - acc: 0.1307 - f1: 0.3795\n",
      "Iteration: 1\n",
      "Failed to load image 679994.jpg\n",
      "x_train shape:  (4000, 299, 299, 3)\n",
      "y_train shape:  (4000, 229)\n",
      "Fine-tuning full model..\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 84s 11s/step - loss: 24.3993 - acc: 0.1283 - f1: 0.3834\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 80s 10s/step - loss: 24.2856 - acc: 0.1280 - f1: 0.3861\n",
      "Iteration: 2\n",
      "Failed to load image 679932.jpg\n",
      "Failed to load image 679873.jpg\n",
      "x_train shape:  (4000, 299, 299, 3)\n",
      "y_train shape:  (4000, 229)\n",
      "Fine-tuning full model..\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 86s 11s/step - loss: 24.0157 - acc: 0.1338 - f1: 0.3977\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 80s 10s/step - loss: 23.8662 - acc: 0.1353 - f1: 0.4025\n",
      "Iteration: 3\n",
      "x_train shape:  (4000, 299, 299, 3)\n",
      "y_train shape:  (4000, 229)\n",
      "Fine-tuning full model..\n",
      "Epoch 1/2\n",
      "8/8 [==============================] - 87s 11s/step - loss: 23.8294 - acc: 0.1345 - f1: 0.4007\n",
      "Epoch 2/2\n",
      "1/8 [==>...........................] - ETA: 1:11 - loss: 23.8034 - acc: 0.1280 - f1: 0.3977"
     ]
    }
   ],
   "source": [
    "no_imgs_batch = 4000 # number of images loaded into memory\n",
    "\n",
    "for iteration in range(int(len(image_files)/no_imgs_batch+1)):\n",
    "    print('Iteration: %s'%iteration)\n",
    "    subset = image_files[(iteration*no_imgs_batch):((iteration+1)*no_imgs_batch)]\n",
    "    indices = [int(image_file.split('.')[0]) for image_file in subset]\n",
    "    \n",
    "    # Load and store features (x_train) in batches\n",
    "    x_train = np.zeros((no_imgs_batch, img_size, img_size, 3))\n",
    "    for i,image_file in enumerate(subset):\n",
    "        try:\n",
    "            image = load_img(os.path.join(train_dir,image_file), target_size=(img_size, img_size))\n",
    "            image = img_to_array(image)\n",
    "            x_train[i,:,:,:] = image\n",
    "        except:\n",
    "            print('Failed to load image %s'%image_file)\n",
    "    #if verbose:\n",
    "    #    print('Batch of size %s loaded..'%no_imgs_batch)\n",
    "\n",
    "    # Load and store labels (y_train)\n",
    "    y_train = train_labels[indices] # full annotations matrix is padded with one zero row and column, and has shape (no_imgs_tot+1,no_labels+1)\n",
    "\n",
    "    if verbose:\n",
    "        print('x_train shape: ', x_train.shape)\n",
    "        print('y_train shape: ', y_train.shape)\n",
    "        \n",
    "    # %%============================================================================\n",
    "    # FINE-TUNE FULL MODEL\n",
    "    #===============================================================================\n",
    "    if verbose:\n",
    "        print('Fine-tuning full model..')\n",
    "\n",
    "    # Structure data with datagenerator (with augmentation)\n",
    "    datagen = ImageDataGenerator(rotation_range=10,\n",
    "                                 width_shift_range=0.15,\n",
    "                                 height_shift_range=0.15,\n",
    "                                 zoom_range=0.15,\n",
    "                                 horizontal_flip=True)\n",
    "\n",
    "    model_full.fit_generator(datagen.flow(x_train, y_train, batch_size=500),\n",
    "                             epochs=2,callbacks=[save_model])\n",
    "                             # steps_per_epoch=no_imgs_batch/32, samples_per_epoch = no_imgs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
